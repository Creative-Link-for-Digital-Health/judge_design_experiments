{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4821054",
   "metadata": {},
   "source": [
    "# Generate Binary Classifications "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "299dc6c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import toml\n",
    "from openai import OpenAI\n",
    "from pathlib import Path\n",
    "import json\n",
    "from typing import Dict, Any, List\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import re\n",
    "\n",
    "sys.path.append('..')\n",
    "\n",
    "from api_utils import load_api_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9ad7a525",
   "metadata": {},
   "outputs": [],
   "source": [
    "SECRETS_PATH = \"../.secrets.toml\" \n",
    "\n",
    "# Model Parameters (change if needed)\n",
    "TEMPERATURE = 0.3\n",
    "STREAM = False\n",
    "\n",
    "MODEL = 'alibayram/medgemma'\n",
    "\n",
    "# load the question-answer turns\n",
    "df_input = pd.read_csv('../inputs/binary_class_2_eval.csv')\n",
    "\n",
    "\n",
    "# Load API parameters and initialize client\n",
    "API_CALL_PARAMS = load_api_params(SECRETS_PATH)\n",
    "client = OpenAI(\n",
    "    base_url=API_CALL_PARAMS['API_URL'],\n",
    "    api_key=API_CALL_PARAMS['API_KEY']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4c62f596",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_completion(model: str, messages: List[Dict[str, str]]) -> str:\n",
    "    response = client.chat.completions.create(\n",
    "        model=model, \n",
    "        messages=messages,\n",
    "        temperature=TEMPERATURE,\n",
    "        stream=STREAM\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "def llm_process(prompt, conversation_turn):\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": prompt},\n",
    "        {\"role\": \"user\", \"content\": conversation_turn}\n",
    "    ]\n",
    "    try:\n",
    "        return generate_completion(MODEL, messages)\n",
    "    except Exception as e:\n",
    "        raise Exception(f\"Error generating completion: {e}\")\n",
    "    \n",
    "def extract_json_from_markdown(text):\n",
    "    # Remove markdown code block formatting\n",
    "    # This pattern looks for ```json ... ```\n",
    "    pattern = r'```json\\s*(.*?)\\s*```'\n",
    "    match = re.search(pattern, text, re.DOTALL)\n",
    "    if match:\n",
    "        return match.group(1)\n",
    "    return text  # Return original if no markdown found\n",
    "\n",
    "def create_conversation_turn(row):\n",
    "    return f\"PersonA: {row['personA_question']} PersonB: {row['personB_answer']}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "831aa85d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_row(row, prompt):\n",
    "    \"\"\"Process each row through the LLM and return results\"\"\"\n",
    "    # Create conversation turn\n",
    "    conversation_turn = create_conversation_turn(row)\n",
    "    \n",
    "    # Process through LLM\n",
    "    llm_result = llm_process(prompt, conversation_turn)\n",
    "    \n",
    "    # Parse the JSON response\n",
    "    try:\n",
    "        json_text = extract_json_from_markdown(llm_result)\n",
    "        parsed_result = json.loads(json_text)\n",
    "        \n",
    "        return {\n",
    "            'turn_id': row['turn_id'],\n",
    "            'original_question': row['personA_question'],\n",
    "            'original_answer': row['personB_answer'],\n",
    "            'conversation_turn': conversation_turn,\n",
    "            'label': parsed_result['label'],\n",
    "            'explanation': parsed_result['explanation']\n",
    "        }\n",
    "    except Exception as e:\n",
    "        return {\n",
    "            'turn_id': row['turn_id'],\n",
    "            'original_question': row['personA_question'],\n",
    "            'original_answer': row['personB_answer'],\n",
    "            'conversation_turn': conversation_turn,\n",
    "            'label': 'ERROR',\n",
    "            'explanation': f'Failed to parse LLM response: {str(e)}'\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c38ea4b4",
   "metadata": {},
   "source": [
    "### Prompt A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2b1252ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./prompts/binary_class_prompt_A.txt', 'r') as file:\n",
    "    prompt_a = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4ad61fba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed turn 1: False\n",
      "Processed turn 2: False\n",
      "Processed turn 3: True\n",
      "Processed turn 4: False\n",
      "Processed turn 5: False\n",
      "Processed turn 6: False\n",
      "Processed turn 7: True\n",
      "Processed turn 8: False\n",
      "Processed turn 9: True\n",
      "Processed turn 10: True\n",
      "\n",
      "Processed 10 conversation turns\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for index, row in df_input.iterrows():\n",
    "    result = process_row(row, prompt_a)\n",
    "    results.append(result)\n",
    "    print(f\"Processed turn {result['turn_id']}: {result['label']}\")\n",
    "\n",
    "# Create DataFrame B with results\n",
    "df_output_A = pd.DataFrame(results)\n",
    "print(f\"\\nProcessed {len(df_output_A)} conversation turns\")\n",
    "\n",
    "# print(df_output_A.head())\n",
    "\n",
    "df_output_A.to_csv('binary_class_judge_output_A.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0892124f",
   "metadata": {},
   "source": [
    "### Prompt B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "cb524e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./prompts/binary_class_prompt_B.txt', 'r') as file:\n",
    "    prompt_b = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a6824060",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed turn 1: False\n",
      "Processed turn 2: True\n",
      "Processed turn 3: True\n",
      "Processed turn 4: False\n",
      "Processed turn 5: False\n",
      "Processed turn 6: False\n",
      "Processed turn 7: True\n",
      "Processed turn 8: False\n",
      "Processed turn 9: True\n",
      "Processed turn 10: True\n",
      "\n",
      "Processed 10 conversation turns\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for index, row in df_input.iterrows():\n",
    "    result = process_row(row, prompt_b)\n",
    "    results.append(result)\n",
    "    print(f\"Processed turn {result['turn_id']}: {result['label']}\")\n",
    "\n",
    "# Create DataFrame B with results\n",
    "df_output_B = pd.DataFrame(results)\n",
    "print(f\"\\nProcessed {len(df_output_B)} conversation turns\")\n",
    "\n",
    "# print(df_output_B.head())\n",
    "\n",
    "df_output_B.to_csv('binary_class_judge_output_B.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-judge",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
